{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laborator 8",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-pub-ro/ML/blob/master/lab/lab8/Laborator_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tmaHAc_KHG_5"
      },
      "source": [
        "# Rețele neurale pentru clasificare imaginilor\n",
        "\n",
        "_Tudor Berariu, 2018_ (tudor.berariu@gmail.com)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKCKTWvsuJuF",
        "colab_type": "text"
      },
      "source": [
        "În cadrul acestui laborator veți implementa o rețea neurală pentru clasificarea imaginilor.\n",
        "Rețeaua va fi compusă din straturi lineare și activări de tip ReLU și un strat softmax înainte de ieșiri. Funcția de cost folosită va fi negative log likelihood. Pentru optimizarea acesteia se va folosi SGD (stochastic gradient descent)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zgNIWhzoHOIz"
      },
      "source": [
        "## 1. Setul de date MNIST\n",
        "\n",
        "Setul de date MNIST este compus din imagini de 28x28 pixeli reprezentând una dintre cele zece cifre 0-9.\n",
        "\n",
        "Decomentați mai jos comanda `!pip install mnist` pentru a instala pachetul `mnist`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dQiqJyO7E7Ek",
        "colab": {}
      },
      "source": [
        "!pip3 install mnist\n",
        "\n",
        "import mnist\n",
        "train_imgs = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "test_imgs = mnist.test_images()\n",
        "test_labels  = mnist.test_labels()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mnist in /home/teo/.local/lib/python3.8/site-packages (0.2.2)\nRequirement already satisfied: numpy in /home/teo/.local/lib/python3.8/site-packages (from mnist) (1.20.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElGfqnPzuJuO",
        "colab_type": "text"
      },
      "source": [
        "### Exemple din setul de date MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qeftJ_CpE7Eu",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy\n",
        "from typing import List\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "avJh9wQquJuU",
        "colab": {}
      },
      "source": [
        "idxs = np.random.randint(0, len(train_imgs), 15)\n",
        "imgs = np.concatenate(tuple(train_imgs[idx,:,:] for idx in idxs), axis=1)\n",
        "plt.imshow(imgs)\n",
        "print(\"Labels:\", train_labels[idxs])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: [6 1 1 5 7 0 2 6 5 3 1 4 3 1 2]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"56.798772pt\" version=\"1.1\" viewBox=\"0 0 368.925 56.798772\" width=\"368.925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-27T17:24:26.948810</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 56.798772 \nL 368.925 56.798772 \nL 368.925 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 32.920647 \nL 361.725 32.920647 \nL 361.725 10.600647 \nL 26.925 10.600647 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pa9a7df0505)\">\n    <image height=\"23\" id=\"image39e25fd01f\" transform=\"scale(1 -1)translate(0 -23)\" width=\"335\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-9.920647\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m8ff83e3542\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"27.323571\" xlink:href=\"#m8ff83e3542\" y=\"32.920647\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(24.142321 47.519085)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"67.180714\" xlink:href=\"#m8ff83e3542\" y=\"32.920647\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <g transform=\"translate(60.818214 47.519085)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"107.037857\" xlink:href=\"#m8ff83e3542\" y=\"32.920647\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <g transform=\"translate(97.494107 47.519085)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"146.895\" xlink:href=\"#m8ff83e3542\" y=\"32.920647\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(137.35125 47.519085)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.752143\" xlink:href=\"#m8ff83e3542\" y=\"32.920647\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <g transform=\"translate(177.208393 47.519085)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"226.609286\" xlink:href=\"#m8ff83e3542\" y=\"32.920647\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g transform=\"translate(217.065536 47.519085)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"266.466429\" xlink:href=\"#m8ff83e3542\" y=\"32.920647\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 300 -->\n      <g transform=\"translate(256.922679 47.519085)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"306.323571\" xlink:href=\"#m8ff83e3542\" y=\"32.920647\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 350 -->\n      <g transform=\"translate(296.779821 47.519085)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"346.180714\" xlink:href=\"#m8ff83e3542\" y=\"32.920647\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 400 -->\n      <g transform=\"translate(336.636964 47.519085)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m64749bdfa3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m64749bdfa3\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.798438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m64749bdfa3\" y=\"30.92779\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 34.727009)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 32.920647 \nL 26.925 10.600647 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 361.725 32.920647 \nL 361.725 10.600647 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 32.920647 \nL 361.725 32.920647 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 10.600647 \nL 361.725 10.600647 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pa9a7df0505\">\n   <rect height=\"22.32\" width=\"334.8\" x=\"26.925\" y=\"10.600647\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFP9QnUJuJuY",
        "colab_type": "text"
      },
      "source": [
        "### Standardizarea datelor\n",
        "\n",
        "Datele de intrare (imaginile) vor fi rescalate pentru a avea media zero și deviația standard 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWmt4XVxuJuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean, std  = train_imgs.mean(), train_imgs.std()\n",
        "train_imgs = (train_imgs - mean) / std\n",
        "test_imgs = (test_imgs - mean) / std"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZgERUA07IuSr"
      },
      "source": [
        "## 2. Construirea unei rețele de tip feed-forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE-V6sONuJud",
        "colab_type": "text"
      },
      "source": [
        "### Notații\n",
        "  - dimensiunea datelor de intrare este $D = 28 * 28 = 784$, iar dimensiunea ieșirilor rețelei este $K=10$ (numărul de clase)\n",
        "  - rețeaua neurală va avea $L$ straturi\n",
        "  - $B$ va reprezenta dimensiunea batch-ului (numărul de exemple trecute în același timp prin rețea)\n",
        "  - Vom nota cu ${\\bf X} \\in {\\mathbb R}^{B \\times D}$ un batch de intrări $\\left\\lbrace {\\bf x}_0, {\\bf x}_1, \\dots {\\bf x}_B \\right\\rbrace$ și similar ${\\bf Y} \\in {\\mathbb R}^{B \\times K}$\n",
        "  - ${\\bf x}^{(l)}$ reprezintă intrările stratului $l$ (${\\bf x}^{(0)}$ va fi o imagine precum cele din setul MNIST de dimensiune $D$)\n",
        "  - ${\\bf y}^{(l)}$ reprezintă ieșirile stratului $l$ (${\\bf y}^{(L-1)}$ reprezintă ieșirile rețelei)\n",
        "  - ${\\bf \\theta}^{(l)}$ reprezintă parametrii stratului $l$\n",
        "  - ${\\cal L}$ reprezintă funcția de cost (_negative log likelihood_)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YTu4tS8uJue",
        "colab_type": "text"
      },
      "source": [
        "### Straturile rețelei\n",
        "\n",
        "Unele straturi au parametri ce trebuie optimizați în timpul antrenării. Vom nota parametrii stratului $l$ cu $\\bf{\\theta}^{(l)}$.\n",
        "Fiecare strat pe care îl veți implementa va avea trei metode:\n",
        " - `forward` calculează și întoarce ${\\bf y}^{(l)} = f_l\\left({\\bf x}^{(l)}, {\\bf \\theta}^{(l)}\\right)$\n",
        " - `backward` primește $\\frac{\\partial {\\cal L}}{\\partial {\\bf y}^{(l)}}$, reține intern $\\frac{\\partial {\\cal L}}{\\partial {\\bf \\theta}^{(l)}}$ și întoarce $\\frac{\\partial {\\cal L}}{\\partial {\\bf x}^{(l)}}$\n",
        " - `update` modifică parametrii locali ${\\bf \\theta}^{(l)}$ folosing gradientul stocat $\\frac{\\partial{\\cal L}}{\\partial{\\bf \\theta}^{(l)}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW206j3euJuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Layer:\n",
        "\n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def backward(self, x: np.ndarray, dy: np.ndarray) -> np.ndarray:\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def update(self, *args, **kwargs):\n",
        "        pass  # If a layer has no parameters, then this function does nothing"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIT6K4IduJuk",
        "colab_type": "text"
      },
      "source": [
        "### Rețeaua neurală\n",
        "\n",
        "  * în faza `forward` ieșirile stratului $l$ devin intrările stratului $l+1$: ${\\bf x}^{(l+1)} = {\\bf y}^{(l)}$\n",
        "  * în faza `backward` gradientul în raport cu intrările stratului $l+1$ devine gradientul în raport cu ieșirile stratului $l$: $\\frac{\\partial {\\cal L}}{\\partial {\\bf y}^{(l)}}=\\frac{\\partial {\\cal L}}{\\partial {\\bf x}^{(l+1)}}$\n",
        "  \n",
        "**[Cerința 0]** Completați metoda `backward` din clasa `FeedForwardNetwork`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTn-g3KAuJul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedForwardNetwork:\n",
        "    \n",
        "    def __init__(self, layers: List[Layer]):\n",
        "        self.layers = layers\n",
        "        \n",
        "    def forward(self, x: np.ndarray, train: bool = True) -> np.ndarray:\n",
        "        self._inputs = []\n",
        "        for layer in self.layers:\n",
        "            if train:\n",
        "                self._inputs.append(x)\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "    \n",
        "    def backward(self, dy:np.ndarray) -> np.ndarray:\n",
        "        # TODO <0> : Compute the backward phase\n",
        "        dx = dy\n",
        "        for i in reversed(range(len(self.layers))):\n",
        "            dx = self.layers[i].backward(self._inputs[i], dx)\n",
        "\n",
        "        del self._inputs\n",
        "        return dx\n",
        "    \n",
        "    def update(self, *args, **kwargs):\n",
        "        for layer in self.layers:\n",
        "            layer.update(*args, **kwargs)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyQLVM4quJup",
        "colab_type": "text"
      },
      "source": [
        "### Stratul linear\n",
        "\n",
        "Un strat linear cu $M$ intrări și $N$ ieșiri are parametrii $\\theta = \\left( {\\bf W}, {\\bf b} \\right)$ unde ${\\bf W} \\in \\mathbb{R}^{M \\times N}$ și ${\\bf b} \\in \\mathbb{R}^{N}$.\n",
        "\n",
        "Pentru un singur exemlu ${\\bf x} \\in {\\mathbb R}^{M}$:\n",
        "$$ {\\bf y} = {\\bf x}^{\\intercal}{\\bf W} + {\\bf b} $$\n",
        "\n",
        "**[Cerința 1]** Implementați metoda `forward` care primește un batch de exemple $X \\in {\\mathbb R}^{B\\times M}$ și întoarce ieșirile corespunzătoare: $Y \\in {\\mathbb R}^{B\\times N}$.\n",
        "\n",
        "**[Cerința 2]** Implementați metoda `backward` care primește un batch de exemple $X \\in {\\mathbb R}^{B\\times M}$ și gradientul în raport cu ieșirile $\\frac{\\partial {\\cal L}}{\\partial {\\bf Y}}$ și realizează două lucruri:\n",
        "  - calculează și salvează intern gradientul $\\frac{\\partial {\\cal L}}{\\partial {\\bf \\theta}}$\n",
        "  - calculează și întoarce gradientul $\\frac{\\partial {\\cal L}}{\\partial {\\bf X}}$\n",
        "  \n",
        "**[BONUS][Cerința 9]** Implementați strategia de optimizare SGD cu _momentum_ (în metoda `update`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S47ZsyKdE7FF",
        "colab": {}
      },
      "source": [
        "class Linear(Layer):\n",
        "    def __init__(self, insize: int, outsize: int) -> None:\n",
        "        bound = np.sqrt(6. / insize)\n",
        "        self.weight = np.random.uniform(-bound, bound, (insize, outsize))\n",
        "        self.bias = np.zeros((outsize,))\n",
        "        \n",
        "        self.dweight = np.zeros_like(self.weight)\n",
        "        self.dbias = np.zeros_like(self.bias)\n",
        "\n",
        "        self.wv = 0\n",
        "        self.bv = 0\n",
        "\n",
        "\n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        # TODO <1> : compute the output of a linear layer\n",
        "        return x @ self.weight + self.bias\n",
        "    \n",
        "    def backward(self, x: np.ndarray, dy: np.ndarray) -> np.ndarray:\n",
        "        # TODO <2> : compute dweight, dbias and return dx\n",
        "        self.dweight = x.T @ dy\n",
        "        self.dbias = np.sum(dy, axis=0)\n",
        "\n",
        "        return dy @ self.weight.T\n",
        "    \n",
        "    def update(self, mode='SGD', lr=0.001, mu=0.9):\n",
        "        if mode == 'SGD':\n",
        "            self.weight -= lr * self.dweight\n",
        "            self.bias -= lr * self.dbias\n",
        "        elif mode == 'momentum':\n",
        "            # TODO <9>: implement momentum update\n",
        "            self.wv = mu * self.wv + lr * self.dweight\n",
        "            self.weight -= self.wv\n",
        "\n",
        "            self.bv = mu * self.bv + lr * self.dbias\n",
        "            self.bias -= self.bv\n",
        "        else:\n",
        "            raise ValueError('mode should be SGD or momentum, not ' + str(mode))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgfHlVgDuJut",
        "colab_type": "text"
      },
      "source": [
        "### The Rectified Linear Unit\n",
        "\n",
        "Stratul ReLU aplică următoare următoare transformare neliniară element cu element:\n",
        "$$y = \\max\\left(x, 0\\right)$$\n",
        "\n",
        "**[Cerințele 3-4]** Implementați metodele `forward` și `backward` pentru un strat de activare ReLU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QOR1DJiwE7FJ",
        "colab": {}
      },
      "source": [
        "class ReLU(Layer):\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "    \n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        # TODO <3> : Compute the output of a rectified linear unit\n",
        "        return np.maximum(x, np.zeros(x.shape))\n",
        "    \n",
        "    def backward(self, x: np.ndarray, dy: np.ndarray) -> np.ndarray:\n",
        "        # TODO <4> : Compute the gradient w.r.t. x\n",
        "        dx = deepcopy(dy)\n",
        "        dx[x <= 0] = 0\n",
        "\n",
        "        return dx"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4NrWBTmbI9gW"
      },
      "source": [
        "## 3. Funcția de cost\n",
        "\n",
        "Funcția de cost pe care o vom folosi este _cross entropy_ care combină un _softmax_ și un cost _negative log-likelihood_. (Matematica la tablă)\n",
        "\n",
        "Dacă ${\\bf y}$ reprezintă ieșrile rețelei pentru o intrare ${\\bf x}$, atunci ${\\bf y}$ va avea o dimensiune egală cu numărul de clase $K$. Atunci probabilitatea (prezisă de rețea) ca exemplul ${\\bf x}$ să aparțină clasei $k$ va fi $p_k$:\n",
        "$$\n",
        "\\begin{align}\n",
        "p_k &= \\frac{e^{y_k}}{\\sum_j e^{y_j}} & & \\text{softmax} \\\\\n",
        "{\\cal L} &= -\\log p_t & & \\text{negative log-likelihood}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "\n",
        "Pentru un batch de dimensiune $B$ se va face media costurilor corespunzătare fiecărui exemplu ($p_k$ este o funcție de ${\\bf x}$ și ${\\bf \\theta}$):\n",
        "\n",
        "$$ {\\cal L} = \\frac{1}{B} \\sum_{({\\bf x}, {\\bf t}) \\in Batch} -\\log p_t \\left({\\bf x}, \\theta\\right) $$\n",
        "\n",
        "**[Cerințele 5-6]** Implementați metodele `forward` și `backward` pentru un funcția de cost _cross-entropy_ (o vom privi ca pe un strat suplimentar)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YDXiDEu8E7FW",
        "colab": {}
      },
      "source": [
        "class CrossEntropy:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def _softmax(self, y, t):\n",
        "        e_t = np.exp([y[i][t[i]] for i in range(len(t))])\n",
        "        return e_t / np.exp(y).sum(axis=1)\n",
        "\n",
        "    def forward(self, y: np.ndarray, t: np.ndarray) -> float:\n",
        "        # TODO <5> : Compute the negative log likelihood\n",
        "        return -np.mean(np.log(self._softmax(y, t)))\n",
        "    \n",
        "    def backward(self, y: np.ndarray, t: np.ndarray) -> np.ndarray:\n",
        "        # TODO <6> : Compute dl/dy\n",
        "        diff = [[yj == y[i][t[i]] for yj in y[i]] for i in range(y.shape[0])]\n",
        "\n",
        "        return [[(np.exp(y[i][j]) / np.sum(np.exp(y[i])) - diff[i][j]) / y.shape[0]\\\n",
        "            for j in range(len(y[i]))] for i in range(len(y))]\n",
        "\n",
        "        return y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uz9qM5eHJLNw"
      },
      "source": [
        "### Acuratețea\n",
        "\n",
        "**[Cerința 7]** Calculați acuratețea predicțiilor ${\\bf y}$ în raport cu clasele corecte ${\\bf t}$ (rația exemplelor pentru care clasa corectă a avut probabilitatea prezisă maximă)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3nYfVCBSE7Fe",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def accuracy(y: np.ndarray, t: np.ndarray) -> float:\n",
        "    return accuracy_score(t, np.argmax(y, axis=1))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mIhtzd2gJQF2"
      },
      "source": [
        "## 4. Antrenarea rețelei neurale\n",
        "\n",
        "**[Cerința 8]** Completați codul de mai jos pentru a calcula gradientul funcției de cost pentru batchul ales și parametrii curenți ai rețelei. _Indiciu_: trebuie să apelați metodele `forward` și `backward` ale rețelei neurale și ale funcției de cost.\n",
        "\n",
        "**[BONUS]** Implementați optimizare cu _momentum_ (vezi TODO-ul numărul 9 din metoda `update`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HTbmZv3YE7Fs",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "HIDDEN_UNITS = 300\n",
        "EPOCHS_NO = 20\n",
        "\n",
        "optimize_args = {'mode': 'momentum', 'lr': .005}\n",
        "\n",
        "net = FeedForwardNetwork([Linear(784, HIDDEN_UNITS),\n",
        "                          ReLU(),\n",
        "                          Linear(HIDDEN_UNITS, 10)])\n",
        "cost_function = CrossEntropy()\n",
        "\n",
        "for epoch in range(EPOCHS_NO):\n",
        "    for b_no, idx in enumerate(range(0, len(train_imgs), BATCH_SIZE)):\n",
        "        # 1. Prepare next batch\n",
        "        x = train_imgs[idx:idx + BATCH_SIZE,:,:].reshape(-1, 784)\n",
        "        t = train_labels[idx:idx + BATCH_SIZE]\n",
        "        \n",
        "        # 2. Compute gradient\n",
        "        \n",
        "        # TODO <8> : Compute gradient\n",
        "        y = net.forward(x, True)\n",
        "        loss = cost_function.forward(y, t)\n",
        "        dy = cost_function.backward(y, t)\n",
        "        dx = net.backward(dy)\n",
        "        \n",
        "        # 3. Update network parameters\n",
        "        net.update(**optimize_args)\n",
        "        \n",
        "        print(f'\\rEpoch {epoch + 1:02d} '\n",
        "              f'| Batch {b_no:03d} '\n",
        "              f'| Train NLL: {loss:6.3f} '\n",
        "              f'| Train Acc: {accuracy(y, t) * 100:6.2f}% ', end='')\n",
        "\n",
        "    y = net.forward(test_imgs.reshape(-1, 784), train=False)\n",
        "    test_nll = cost_function.forward(y, test_labels)\n",
        "    print(f'| Test NLL: {test_nll:6.3f} '\n",
        "          f'| Test Acc: {accuracy(y, test_labels) * 100:3.2f}%')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Batch 468 | Train NLL:  0.264 | Train Acc:  96.88% | Test NLL:  0.210 | Test Acc: 93.64%\n",
            "Epoch 02 | Batch 468 | Train NLL:  0.208 | Train Acc:  97.92% | Test NLL:  0.154 | Test Acc: 95.35%\n",
            "Epoch 03 | Batch 468 | Train NLL:  0.185 | Train Acc:  98.96% | Test NLL:  0.129 | Test Acc: 96.04%\n",
            "Epoch 04 | Batch 468 | Train NLL:  0.171 | Train Acc:  98.96% | Test NLL:  0.115 | Test Acc: 96.53%\n",
            "Epoch 05 | Batch 468 | Train NLL:  0.160 | Train Acc:  98.96% | Test NLL:  0.106 | Test Acc: 96.77%\n",
            "Epoch 06 | Batch 468 | Train NLL:  0.152 | Train Acc:  98.96% | Test NLL:  0.099 | Test Acc: 96.88%\n",
            "Epoch 07 | Batch 468 | Train NLL:  0.145 | Train Acc:  98.96% | Test NLL:  0.094 | Test Acc: 97.09%\n",
            "Epoch 08 | Batch 468 | Train NLL:  0.139 | Train Acc:  98.96% | Test NLL:  0.090 | Test Acc: 97.18%\n",
            "Epoch 09 | Batch 468 | Train NLL:  0.133 | Train Acc:  98.96% | Test NLL:  0.087 | Test Acc: 97.26%\n",
            "Epoch 10 | Batch 468 | Train NLL:  0.127 | Train Acc:  98.96% | Test NLL:  0.084 | Test Acc: 97.40%\n",
            "Epoch 11 | Batch 468 | Train NLL:  0.121 | Train Acc:  98.96% | Test NLL:  0.082 | Test Acc: 97.47%\n",
            "Epoch 12 | Batch 468 | Train NLL:  0.116 | Train Acc:  98.96% | Test NLL:  0.080 | Test Acc: 97.55%\n",
            "Epoch 13 | Batch 468 | Train NLL:  0.109 | Train Acc:  98.96% | Test NLL:  0.078 | Test Acc: 97.57%\n",
            "Epoch 14 | Batch 468 | Train NLL:  0.104 | Train Acc:  98.96% | Test NLL:  0.077 | Test Acc: 97.67%\n",
            "Epoch 15 | Batch 468 | Train NLL:  0.098 | Train Acc:  98.96% | Test NLL:  0.076 | Test Acc: 97.70%\n",
            "Epoch 16 | Batch 468 | Train NLL:  0.092 | Train Acc:  98.96% | Test NLL:  0.074 | Test Acc: 97.73%\n",
            "Epoch 17 | Batch 468 | Train NLL:  0.087 | Train Acc:  98.96% | Test NLL:  0.073 | Test Acc: 97.77%\n",
            "Epoch 18 | Batch 468 | Train NLL:  0.082 | Train Acc:  98.96% | Test NLL:  0.072 | Test Acc: 97.81%\n",
            "Epoch 19 | Batch 468 | Train NLL:  0.076 | Train Acc:  98.96% | Test NLL:  0.072 | Test Acc: 97.80%\n",
            "Epoch 20 | Batch 468 | Train NLL:  0.071 | Train Acc:  98.96% | Test NLL:  0.071 | Test Acc: 97.81%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7zGgHlduJvA",
        "colab_type": "text"
      },
      "source": [
        "## Teste\n",
        "\n",
        "Executați ```test0() and test16() and test7()``` pentru a rula testele."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YaLsPBfuJvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test0():\n",
        "    fakex = [np.random.randn(128, n) for n in [20, 40, 30, 10]]\n",
        "\n",
        "    class DummyLayer:\n",
        "        def __init__(self, idx):\n",
        "            self.idx = idx\n",
        "\n",
        "        def forward(self, x):\n",
        "            return fakex[self.idx + 1]\n",
        "\n",
        "        def backward(self, x, dldy):\n",
        "            if not np.allclose(x, fakex[self.idx]):\n",
        "                raise Exception(\"Intrări greșite în backward\")\n",
        "            if not np.allclose(dldy, -fakex[self.idx+1]):\n",
        "                raise Exception(\"Intrări greșite în backward\")\n",
        "            return -x\n",
        "\n",
        "    try:\n",
        "        net = FeedForwardNetwork([DummyLayer(i) for i in range(3)])\n",
        "        net.forward(fakex[0])\n",
        "        net.backward(-fakex[-1])\n",
        "        print(\"Cerința 0 rezolvată corect!\")\n",
        "        return True\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 0 nu a fost implementată!\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 0 are erori.\")\n",
        "        \n",
        "    return False\n",
        "        \n",
        "def test16():\n",
        "    __x = np.array([[-3.0731, -1.9081, -0.7283, -0.0757, -0.7577],\n",
        "                    [ 2.4041, -1.1506, -0.5924,  1.3016,  1.0882],\n",
        "                    [-0.5254,  0.3519, -0.9633, -2.7393, -0.9745]])\n",
        "    __w = np.array([[ 1.3214, -0.5886, -0.0351,  1.2084,  1.2661, -0.9979, -0.1172],\n",
        "                    [-0.4022,  0.1168,  0.9020, -2.0098, -0.5409, -0.3876, -0.1719],\n",
        "                    [-1.1125, -0.5556,  0.8843,  0.6995,  0.4929,  0.7523,  0.1832],\n",
        "                    [ 0.2267,  0.6757,  1.1286, -0.3218,  1.6934, -0.1782, -0.3467],\n",
        "                    [-0.6062,  0.4426,  0.5090,  0.4772, -0.5721,  0.8658, -0.5999]])\n",
        "    __b = np.array([ 0.3335,  0.5051, -0.1393,  1.2116,  1.7836, -0.6597,  0.3553])\n",
        "    __y = np.array([[-1.70746622, 2.10919555, -2.8676804, 0.48630531, -1.1288499, 1.95609904, 1.39083457],\n",
        "                    [4.26749994, 0.64592254, 0.23749513, 6.11524068, 6.73936681, -2.34822291, -0.94127596],\n",
        "                    [0.5391161, -0.89159687, -4.24288533, -0.38789499, -3.62798139, -1.35206921, 1.71422657]])\n",
        "    \n",
        "    __dy = np.array([[ 1.5555, -0.8978, -0.2917, -0.3868, -0.8257, -0.3491, -0.8658],\n",
        "                     [ 1.1146,  1.4914,  0.9591, -0.2613,  0.5887,  0.4794,  0.8565],\n",
        "                     [-0.1552, -1.6319,  1.7642,  1.0503,  0.1035 , -0.7186, -0.9782]])\n",
        "    __dx = np.array([[ 1.53113221,  0.51455541, -2.588423,   -1.49460989, -0.98384103],\n",
        "                     [ 0.41215308,  0.46469672, -0.59552791,  3.04147235, -0.08763244],\n",
        "                     [ 2.92549149, -0.25707023,  2.70531668,  1.15769427,  0.67643021]])\n",
        "    __dw = np.array(\n",
        "        [[-2.01905511,  7.20190418,  2.2752849,   0.00865613,  3.89837344,  2.60289719, 5.23374791],\n",
        "         [-4.30512319, -0.57717827,  0.07387429,  1.40830543,  0.9345816,  -0.13835527, 0.3223155 ],\n",
        "         [-1.64365553,  1.34237165, -2.05517959, -0.57525343,  0.15290988,  0.66248035, 1.0654716 ],\n",
        "         [ 1.75815137,  6.47943337, -3.56222681, -3.18791411,  0.54523986,  2.61887489, 3.85994472],\n",
        "         [ 0.18554777,  3.89349109, -0.45449919, -1.01478565,  1.16539548,  1.48647185, 2.54131586]]\n",
        "    )\n",
        "    __db = np.array([ 2.5149, -1.0383,  2.4316,  0.4022, -0.1335, -0.5883, -0.9875])\n",
        "    \n",
        "    __y_relu = np.array([[0, 2.10919555, 0, 0.48630531, 0, 1.95609904, 1.39083457],\n",
        "                         [4.26749994, 0.64592254, 0.23749513, 6.11524068, 6.73936681, 0, 0],\n",
        "                         [0.5391161, 0, 0, 0, 0, 0, 1.71422657]])\n",
        "    __drelu = np.array([[0, -0.8978, 0, -0.3868, 0, -0.3491, -0.8658],\n",
        "                        [ 1.1146,  1.4914,  0.9591, -0.2613,  0.5887,  0,  0],\n",
        "                        [-0.1552, 0,  0,  0,  0 , 0, -0.9782]])\n",
        "    \n",
        "    __t = np.array([3, 1, 2])\n",
        "    __dl_dy = np.array(\n",
        "        [[ 2.80870645e-03,  1.27661957e-01,  8.80302096e-04, -3.08142112e-01,\n",
        "           5.00952130e-03,  1.09539948e-01,  6.22416775e-02],\n",
        "         [ 1.73238217e-02, -3.32870086e-01,  3.07917841e-04,  1.09927743e-01,\n",
        "           2.05192672e-01,  2.31991342e-05,  9.47329526e-05],\n",
        "         [ 6.60308812e-02,  1.57905168e-02, -3.32780047e-01,  2.61307149e-02,\n",
        "           1.02329216e-03,  9.96358772e-03,  2.13841054e-01]]\n",
        "    )\n",
        "\n",
        "\n",
        "    try:\n",
        "        lin = Linear(5, 7)\n",
        "        lin.weight = __w.copy()\n",
        "        lin.bias = __b.copy()\n",
        "        y = lin.forward(__x.copy())\n",
        "        if not np.allclose(y, __y):\n",
        "            raise Exception(\"Ieșiri greșite\")\n",
        "        print(\"Cerința 1 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 1 nu a fost implementată!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 1 are erori.\")\n",
        "        return False\n",
        "        \n",
        "    try:\n",
        "        dx = lin.backward(__x.copy(), __dy.copy())\n",
        "        if not np.allclose(dx, __dx):\n",
        "            raise ValueError(\"dL/dx greșit\")\n",
        "        if not np.allclose(lin.dweight, __dw):\n",
        "            raise ValueError(\"dL/dw greșit\")\n",
        "        if not np.allclose(lin.dbias, __db):\n",
        "            raise ValueError(\"dL/db greșit\")\n",
        "        print(\"Cerința 2 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 2 nu a fost implementată!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 2 are erori.\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        relu = ReLU()\n",
        "        y_relu = relu.forward(__y.copy())\n",
        "        if not np.allclose(y_relu, __y_relu):\n",
        "            raise ValueError(\"ReLU(x) greșit\")\n",
        "        print(\"Cerința 3 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 3 nu a fost implementată!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 3 are erori.\")\n",
        "        return False\n",
        "            \n",
        "    try:\n",
        "        relu = ReLU()\n",
        "        drelu = relu.backward(__y.copy(), __dy.copy())\n",
        "        if not np.allclose(drelu, __drelu):\n",
        "            raise ValueError(\"ReLU.backward greșit\")\n",
        "        print(\"Cerința 4 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 4 nu a fost implementată!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 4 are erori.\")\n",
        "        return False\n",
        "    \n",
        "    try:\n",
        "        ce = CrossEntropy()\n",
        "        loss = ce.forward(__y.copy(), __t.copy())\n",
        "        if np.abs(loss - 5.1874357237332545) > 1e-6:\n",
        "            raise ValueError(f\"Valoare greșită nll: {loss:f} în loc de 5.1874357237332545\")\n",
        "        print(\"Cerința 5 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 5 nu a fost implementată!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 5 are erori.\")\n",
        "        return False\n",
        "    \n",
        "    try:\n",
        "        ce = CrossEntropy()\n",
        "        dl_dy = ce.backward(__y.copy(), __t.copy())\n",
        "        if not np.allclose(dl_dy, __dl_dy) > 1e-6:\n",
        "            raise ValueError(f\"Valoare greșită pentru dNLL/dy\")\n",
        "        print(\"Cerința 6 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 6 nu a fost implementată!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 6 are erori.\")\n",
        "        return False\n",
        "    \n",
        "    return True\n",
        "\n",
        "def test7():  # Acuratețea\n",
        "    y = np.array([[ 0.6460014 , -0.05876393, -1.36496105, -0.07057596,  0.54938383],\n",
        "                  [-0.8033942 , -0.51753041,  0.92278036, -1.66303585, -0.36537512],\n",
        "                  [-1.3710599 ,  0.65598193, -0.75527154,  1.21609284,  0.08284123],\n",
        "                  [-1.24696857,  0.32676634,  0.09572539,  1.38316398, -0.14110726],\n",
        "                  [-2.01698315,  2.06123375, -1.68003675,  0.0504592 ,  0.04427597],\n",
        "                  [-0.8893451 ,  1.74695148, -0.29394473,  0.74203068, -0.75185261],\n",
        "                  [ 1.34126333, -0.5272606 ,  1.46458319,  1.59529987,  1.86884676],\n",
        "                  [-0.58987297,  1.10900165, -0.71208103,  0.20478154, -1.26693567],\n",
        "                  [-2.17730677, -1.36147532, -1.49679182,  0.24812177, -0.13368035],\n",
        "                  [-0.48730599,  1.31710647,  0.41765538,  1.19869192, -0.05301611],\n",
        "                  [-0.10655224, -0.21174034,  1.31548647, -0.57990281,  0.85868472],\n",
        "                  [-0.32055613, -2.17817118, -0.28488692,  1.62977524,  0.25150929],\n",
        "                  [ 0.07704727,  1.67710047,  1.83368441, -0.45456845, -0.74474969]])\n",
        "    t = np.array([0, 2, 3, 3, 1, 0, 1, 1, 2, 1, 2, 3, 2])\n",
        "    try:\n",
        "        acc = accuracy(y, t)\n",
        "        if np.abs(acc - 0.7692307692307693) > 1e-7:\n",
        "            raise ValueError(f\"{acc:f} != 10/13\")\n",
        "        print(f\"Cerința 7 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 7 nu a fost implementată!\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 7 are erori.\")\n",
        "    "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWQ2e7C4uJvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test0() and test16() and test7()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cerința 0 rezolvată corect!\nCerința 1 rezolvată corect!\nCerința 2 rezolvată corect!\nCerința 3 rezolvată corect!\nCerința 4 rezolvată corect!\nCerința 5 rezolvată corect!\nCerința 6 rezolvată corect!\nCerința 7 rezolvată corect!\n"
          ]
        }
      ]
    }
  ]
}